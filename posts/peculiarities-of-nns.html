<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="Dillon Laird&#x27;s Blog" content=""/><meta property="og:image" content="https://og-image.vercel.app/Dillon%20Laird&#x27;s%20Blog.png?theme=light&amp;md=0&amp;fontSize=75px&amp;images=https%3A%2F%2Fassets.zeit.co%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fnextjs-black-logo.svg"/><meta name="og:title" content="Dillon Laird&#x27;s Blog"/><meta name="twitter:card" content="summary_large_image"/><link rel="preload" as="image" href="/images/headshot.jpg" fetchpriority="high"/><title>The Peculiarities of Training Neural Networks</title><meta name="next-head-count" content="9"/><link rel="preload" href="/dillonalaird.github.io/_next/static/css/0275f6d90e7ad339.css" as="style"/><link rel="stylesheet" href="/dillonalaird.github.io/_next/static/css/0275f6d90e7ad339.css" data-n-g=""/><link rel="preload" href="/dillonalaird.github.io/_next/static/css/c39f9723b4064ac0.css" as="style"/><link rel="stylesheet" href="/dillonalaird.github.io/_next/static/css/c39f9723b4064ac0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/dillonalaird.github.io/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/dillonalaird.github.io/_next/static/chunks/webpack-d932a5e3ea7c2e1f.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/chunks/main-816956006f21d184.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/chunks/pages/_app-2d6bf7b3192a8752.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/chunks/112-f23852e9772edec7.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/chunks/pages/posts/%5Bid%5D-6f5fa4b649eff832.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/qGpT8korstTr9M729SIpI/_buildManifest.js" defer=""></script><script src="/dillonalaird.github.io/_next/static/qGpT8korstTr9M729SIpI/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_container__fbLkO"><header class="layout_header__kY0Lt"><a href="/dillonalaird.github.io"><img alt="Dillon Laird" fetchpriority="high" width="108" height="108" decoding="async" data-nimg="1" class="utils_borderCircle__s2nTm" style="color:transparent" src="/images/headshot.jpg"/></a><h2 class="utils_headingLg__5535D"><a class="utils_colorInherit__mSH_x" href="/dillonalaird.github.io">Dillon Laird</a></h2></header><main><article><h1 class="utils_headingXl__u25Y2">The Peculiarities of Training Neural Networks</h1><div class="utils_lightText__eUzGY"><time dateTime="2017-07-04">July 4, 2017</time></div><div><p>Neural networks are notoriously difficult to train. They can completely diverge
on one set of parameters and get state-of-the-art results on a slightly
different set of parameters. Over the years I’ve learned several tricks to
training neural networks. A lot of these tricks are well kept secrets in
industry and academics and I think it’s time the rest of the world learned how
neural networks are really trained. So at the risk of being excommunicated from
the deep learning community, here is my write up of the peculiarities of
training neural networks.</p>
<p>While the advancement of artificial intelligence (AI) has led neural networks
closer to obtaining human intelligence, not all networks have moved towards this
path in a straight line. Some networks have also attained more undesirable human
attributes. These are often little discussed and even brushed under the rug for
fear of embarrassment to the deep learning community. But here, I finally
present a formal discussion of some of these abnormalities of training neural
networks.</p>
<h2>Cat Images</h2>
<p><img src="/images/cat.png" alt=""></p>
<p>It’s been well known in the deep learning community for a long time that
training neural networks on cat images actually improves performance. Like many
other oddities of neural networks, researchers have absolutely no clue why this
is the case but has been well documented in many amateur papers posted on arxiv.
Some have attributed to happier gradient flows, which have an easier time
updating the weights than say melancholy gradient flows, or gradient flows that
haven’t had their morning coffee. In some instances, researchers have posted
accuracy gains up to 2% on ImageNet. In more recent work, researchers have also
found that feeding the network pictures of Donald Trump led to a whopping 5%
decrease in accuracy. When researchers investigated further, they found that the
network predicted “baboon” about 5% of the time.</p>
<h2>"Humbling" Your Network</h2>
<p>Some of the more recent networks achieving state-of-the-art results have become
very large and require a lot of hardware to train them. This has led to these
networks developing a slight ego which leads to many issues during test time.
For example Google’s GNMT is known to be an arrogant network because it requires
$500,000 of equipment to train. You might ask it to translate “The duck says
quack.” to German, to which it either outputs “...” or “Really? You want me to
translate that?”. One way to fix this is by humbling your network. You can do
this by feeding it sentences such as, “You’re not that good.” or “You could get
replaced by a linear model and no one would know the difference.” or even “I
could not anneal the learning rate and watch you diverge at any minute.”. For
most people though arrogant networks are not an issue, since only Google runs
their models on half a million dollars of equipment for a month to get
state-of-the-art.</p>
<h2>Ritual Sacrifice</h2>
<p><img src="/images/nvidia.png" alt=""></p>
<p>Ever wonder how deep learning researchers find those obscure hyperparameters? In
school they’ll tell you it’s random searching but there’s a much darker secret
behind them. One way to accomplish this is to sacrifice a GPU before you run
your random hyperparameter search. You can do this by creating a fire sigil on
the ground in the shape of the Nvidia logo and then burning a GPU in the middle
of it. The better the GPU, the better the hyperparameters. It’s rumored that
Google sacrificed 3 Titan X’s to obtain their hyperparameters for “Google’s
Neural Machine Translation System” paper. Since a typical run takes 6 days to
train on 96 NVIDIA K80 GPUs these would have been near impossible to find
otherwise.</p>
<h2>Home Field Advantage</h2>
<p>Another well kept secret at Google is that the closer Jeff Dean is to your GPU
cluster, the faster it runs. This is the real reason Google started developing
the TPU, as an insurance policy for when Jeff Dean leaves. Other large companies
also have their own in house advantage. Yann Lecun gives +3 BLEU score to French
translation models when sitting near the GPUs.</p>
</div></article></main><div class="layout_backToHome__9sjx_"><a href="/dillonalaird.github.io">← Back to home</a></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"peculiarities-of-nns","contentHtml":"\u003cp\u003eNeural networks are notoriously difficult to train. They can completely diverge\non one set of parameters and get state-of-the-art results on a slightly\ndifferent set of parameters. Over the years I’ve learned several tricks to\ntraining neural networks. A lot of these tricks are well kept secrets in\nindustry and academics and I think it’s time the rest of the world learned how\nneural networks are really trained. So at the risk of being excommunicated from\nthe deep learning community, here is my write up of the peculiarities of\ntraining neural networks.\u003c/p\u003e\n\u003cp\u003eWhile the advancement of artificial intelligence (AI) has led neural networks\ncloser to obtaining human intelligence, not all networks have moved towards this\npath in a straight line. Some networks have also attained more undesirable human\nattributes. These are often little discussed and even brushed under the rug for\nfear of embarrassment to the deep learning community. But here, I finally\npresent a formal discussion of some of these abnormalities of training neural\nnetworks.\u003c/p\u003e\n\u003ch2\u003eCat Images\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/cat.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eIt’s been well known in the deep learning community for a long time that\ntraining neural networks on cat images actually improves performance. Like many\nother oddities of neural networks, researchers have absolutely no clue why this\nis the case but has been well documented in many amateur papers posted on arxiv.\nSome have attributed to happier gradient flows, which have an easier time\nupdating the weights than say melancholy gradient flows, or gradient flows that\nhaven’t had their morning coffee. In some instances, researchers have posted\naccuracy gains up to 2% on ImageNet. In more recent work, researchers have also\nfound that feeding the network pictures of Donald Trump led to a whopping 5%\ndecrease in accuracy. When researchers investigated further, they found that the\nnetwork predicted “baboon” about 5% of the time.\u003c/p\u003e\n\u003ch2\u003e\"Humbling\" Your Network\u003c/h2\u003e\n\u003cp\u003eSome of the more recent networks achieving state-of-the-art results have become\nvery large and require a lot of hardware to train them. This has led to these\nnetworks developing a slight ego which leads to many issues during test time.\nFor example Google’s GNMT is known to be an arrogant network because it requires\n$500,000 of equipment to train. You might ask it to translate “The duck says\nquack.” to German, to which it either outputs “...” or “Really? You want me to\ntranslate that?”. One way to fix this is by humbling your network. You can do\nthis by feeding it sentences such as, “You’re not that good.” or “You could get\nreplaced by a linear model and no one would know the difference.” or even “I\ncould not anneal the learning rate and watch you diverge at any minute.”. For\nmost people though arrogant networks are not an issue, since only Google runs\ntheir models on half a million dollars of equipment for a month to get\nstate-of-the-art.\u003c/p\u003e\n\u003ch2\u003eRitual Sacrifice\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/nvidia.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eEver wonder how deep learning researchers find those obscure hyperparameters? In\nschool they’ll tell you it’s random searching but there’s a much darker secret\nbehind them. One way to accomplish this is to sacrifice a GPU before you run\nyour random hyperparameter search. You can do this by creating a fire sigil on\nthe ground in the shape of the Nvidia logo and then burning a GPU in the middle\nof it. The better the GPU, the better the hyperparameters. It’s rumored that\nGoogle sacrificed 3 Titan X’s to obtain their hyperparameters for “Google’s\nNeural Machine Translation System” paper. Since a typical run takes 6 days to\ntrain on 96 NVIDIA K80 GPUs these would have been near impossible to find\notherwise.\u003c/p\u003e\n\u003ch2\u003eHome Field Advantage\u003c/h2\u003e\n\u003cp\u003eAnother well kept secret at Google is that the closer Jeff Dean is to your GPU\ncluster, the faster it runs. This is the real reason Google started developing\nthe TPU, as an insurance policy for when Jeff Dean leaves. Other large companies\nalso have their own in house advantage. Yann Lecun gives +3 BLEU score to French\ntranslation models when sitting near the GPUs.\u003c/p\u003e\n","title":"The Peculiarities of Training Neural Networks","date":"2017-07-04"}},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"peculiarities-of-nns"},"buildId":"qGpT8korstTr9M729SIpI","assetPrefix":"/dillonalaird.github.io","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>